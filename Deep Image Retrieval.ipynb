{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "UHZ_XzcZm3Up"
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ7tNv_mmtUr"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "import cv2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from typing import Tuple\n",
    "from pytorch_metric_learning import losses\n",
    "import timm\n",
    "from torch_lr_finder import LRFinder\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg\n",
    "import joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "ILJNX-llm5Yk"
   },
   "source": [
    "## Checking GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking cuda stats and avialability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using\", device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Data Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data from train and query folders\n",
    "def load_data(train_path, query_path, names):\n",
    "    train_image_paths = []\n",
    "    train_classes = []\n",
    "\n",
    "    # save path to image and save class names as numbers (train)\n",
    "    for data_path in glob.glob(train_path + '/*'):\n",
    "        name = data_path.split('/')[-1].split(\"-\")[0]\n",
    "        idx = names.index(name)\n",
    "        train_classes.append(idx) \n",
    "        train_image_paths.append(data_path)\n",
    "\n",
    "    # save path to image and save class names as numbers (query)\n",
    "    valid_image_paths = []\n",
    "    valid_classes = []\n",
    "    for data_path in glob.glob(query_path + '/*'):\n",
    "        name = data_path.split('/')[-1].split(\"-\")[0]\n",
    "        idx = names.index(name)\n",
    "        valid_classes.append(idx) \n",
    "        valid_image_paths.append(data_path)\n",
    "\n",
    "    print(\"Train Images: {} | Query Images: {}\".format(len(train_image_paths), len(valid_image_paths)))\n",
    "    return train_image_paths, train_classes, valid_image_paths, valid_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data function\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset function for loading images and classes in\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, train=False):\n",
    "        self.is_train = train\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        anchor_image = Image.open(image_filepath)\n",
    "        anchor_label = self.labels[idx]\n",
    "        \n",
    "        if self.is_train:\n",
    "            if self.transform is not None:\n",
    "                anchor_image = self.transform(anchor_image)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                anchor_image = self.transform(anchor_image)\n",
    "        return anchor_image, anchor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images function:\n",
    "def imshow(img, title=None):\n",
    "     # unnormalize img and display\n",
    "    img = img / 2 + 0.5\n",
    "    img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "    img = cv2.normalize(img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    img = img.astype(np.uint8)\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(dataloader, n_samples=5):\n",
    "    # get some random training images\n",
    "    dataiter = iter(dataloader)\n",
    "    anchors, label = dataiter.next()\n",
    "    # show anchor, pos, neg, images\n",
    "    imshow(torchvision.utils.make_grid(anchors[:n_samples]), \"Anchor Images\")\n",
    "\n",
    "    # print labels\n",
    "    print(\"Labels\")\n",
    "    print([names[idx] for idx in label[:n_samples]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Fine Tuning functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning model parameters\n",
    "def fine_tune(dataloader, model, epochs=1, lr=0.00005):\n",
    "\n",
    "    criterion = losses.CircleLoss(m=0.4, gamma=80)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-6)\n",
    "    \n",
    "    iteration_loss = []\n",
    "    epoch_loss = []\n",
    "    maps = []\n",
    "    \n",
    "    # method to update weights in given model \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = []\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            anchor, anchor_label = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            anchor_out = model(anchor)\n",
    "                        \n",
    "            loss = criterion(anchor_out, anchor_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            anchor_out.detach()\n",
    "                \n",
    "            # print statistics\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "            iteration_loss.append(loss.cpu().detach().numpy())\n",
    "        epoch_loss.append(np.mean(running_loss))\n",
    "        \n",
    "        # setting a model checkpoint to compute mAP:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, \"checkpoint\")\n",
    "\n",
    "        model.eval()\n",
    "        trn_features, trn_names, val_features, val_names, AP, precisionsatk, mAP = compute_map(model, 'oxford', 'easy', 0, 0, False)\n",
    "        maps.append(mAP)\n",
    "        \n",
    "        checkpoint = torch.load(\"checkpoint\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])    \n",
    "\n",
    "        print(\"Epoch: {}/{} - Loss: {:.4f} - mAP: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss), maps[-1]))\n",
    "\n",
    "    print('Finished Training')\n",
    "    return iteration_loss, epoch_loss, maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(iteration_loss, epoch_loss, maps):\n",
    "    plt.plot(iteration_loss)\n",
    "    plt.title(\"Loss over each iteration\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epoch_loss) \n",
    "    plt.title(\"Loss over each epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(maps)\n",
    "    plt.title(\"mAP over each epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "_e_YJE0IYZCn"
   },
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(mod):\n",
    "    if mod == 'vgg':\n",
    "        out_model = vgg16_bn(pretrained=True)\n",
    "        out_model.classifier = out_model.classifier[:4] \n",
    "    elif mod == 'resnet':\n",
    "        out_model = resnet50(pretrained=True)\n",
    "        out_model.fc = nn.Identity()\n",
    "    elif mod == 'swin':\n",
    "        out_model = timm.create_model('swin_large_patch4_window7_224_in22k', pretrained=True)\n",
    "        out_model.head = nn.Identity()\n",
    "    elif mod == 'vit':\n",
    "        out_model = timm.create_model('vit_large_patch16_224_in21k', pretrained=True)\n",
    "        out_model.head = nn.Identity()\n",
    "    elif mod == 'mae_vit':\n",
    "        out_model = timm.create_model('vit_large_patch16_224_in21k')\n",
    "        mae_pretrianed = torch.load('Saved_models/mae_pretrain_vit_large.pth')\n",
    "        out_model.load_state_dict(mae_pretrianed['model'], strict=False)\n",
    "    else:\n",
    "        print(\"Unknown Model: Try 'vgg' or 'resnet' or 'vit' or 'swin' or 'mae_vit'\")\n",
    "        out_model = None\n",
    "    return out_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ft(m, mod, dataset):\n",
    "    checkpoint = torch.load(\"Saved_models/{}-{}-model\".format(mod, dataset))\n",
    "    m.load_state_dict(checkpoint['model_state_dict'])  \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Loading ROxford5k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy data\n",
    "ox_train_path = \"roxford5k/easy\"\n",
    "ox_query_path = \"roxford5k/query\"\n",
    "ox_names = ['radcliffe_camera','hertford','all_souls','bodleian','balliol','magdalen','christ_church','pitt_rivers','ashmolean','keble','cornmarket']\n",
    "ox_easy_image_paths, ox_easy_classes, ox_query_image_paths, ox_query_classes = load_data(ox_train_path, ox_query_path, ox_names)\n",
    "\n",
    "ox_easy_dataset = Dataset(ox_easy_image_paths, ox_easy_classes, data_transforms, True)\n",
    "ox_query_dataset = Dataset(ox_query_image_paths, ox_query_classes, data_transforms, False)\n",
    "\n",
    "ox_easy_loader = DataLoader(ox_easy_dataset , batch_size=32, shuffle=True)\n",
    "ox_query_loader = DataLoader(ox_query_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard data\n",
    "ox_train_path = \"roxford5k/hard\"\n",
    "ox_hard_image_paths, ox_hard_classes, ox_query_image_paths, ox_query_classes = load_data(ox_train_path, ox_query_path, ox_names)\n",
    "\n",
    "ox_hard_dataset = Dataset(ox_hard_image_paths, ox_hard_classes, data_transforms, True)\n",
    "\n",
    "ox_hard_loader = DataLoader(ox_hard_dataset , batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium data\n",
    "ox_medium_image_paths = ox_hard_image_paths + ox_easy_image_paths\n",
    "ox_medium_classes = ox_hard_classes + ox_easy_classes\n",
    "\n",
    "ox_medium_dataset = Dataset(ox_medium_image_paths, ox_medium_classes, data_transforms, True)\n",
    "\n",
    "ox_medium_loader = DataLoader(ox_medium_dataset , batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load junk images in:\n",
    "ox_train_path = \"roxford5k/junk\"\n",
    "ox_junk_image_paths, ox_junk_classes, ox_query_image_paths, ox_query_classes = load_data(ox_train_path, ox_query_path, ox_names)\n",
    "\n",
    "# combine all images (medium with junk):\n",
    "ox_all_image_paths = ox_medium_image_paths + ox_junk_image_paths\n",
    "ox_all_classes = ox_medium_classes + ox_junk_classes\n",
    "\n",
    "# make full dataset and loader:\n",
    "ox_all_dataset = Dataset(ox_all_image_paths, ox_all_classes, data_transforms, True)\n",
    "ox_all_loader = DataLoader(ox_all_dataset , batch_size=32, shuffle=True)\n",
    "\n",
    "print(\"Train Images: {} | Query Images: {}\".format(len(ox_all_image_paths), len(ox_query_image_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Loading RParis6k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy data\n",
    "par_train_path = \"rparis6k/easy\"\n",
    "par_query_path = \"rparis6k/query\"\n",
    "par_names = [\"defense\", \"eiffel\", \"invalides\",\"louvre\",\"moulinrouge\",\"museedorsay\",\"notredame\",\"pantheon\",\"pompidou\",\"sacrecoeur\",\"triomphe\",]\n",
    "par_easy_image_paths, par_easy_classes, par_query_image_paths, par_query_classes = load_data(par_train_path, par_query_path, par_names)\n",
    "\n",
    "par_easy_dataset = Dataset(par_easy_image_paths, par_easy_classes, data_transforms, True)\n",
    "par_query_dataset = Dataset(par_query_image_paths, par_query_classes, data_transforms, False)\n",
    "\n",
    "par_easy_loader = DataLoader(par_easy_dataset , batch_size=32, shuffle=True)\n",
    "par_query_loader = DataLoader(par_query_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard data\n",
    "par_train_path = \"rparis6k/hard\"\n",
    "par_hard_image_paths, par_hard_classes, par_query_image_paths, par_query_classes = load_data(par_train_path, par_query_path, par_names)\n",
    "\n",
    "par_hard_dataset = Dataset(par_hard_image_paths, par_hard_classes, data_transforms, True)\n",
    "\n",
    "par_hard_loader = DataLoader(par_hard_dataset , batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium data\n",
    "par_medium_image_paths = par_hard_image_paths + par_easy_image_paths\n",
    "par_medium_classes = par_hard_classes + par_easy_classes\n",
    "\n",
    "par_medium_dataset = Dataset(par_medium_image_paths, par_medium_classes, data_transforms, True)\n",
    "\n",
    "par_medium_loader = DataLoader(par_medium_dataset , batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load junk images in:\n",
    "par_train_path = \"rparis6k/junk\"\n",
    "par_junk_image_paths, par_junk_classes, par_query_image_paths, par_query_classes = load_data(par_train_path, par_query_path, par_names)\n",
    "\n",
    "# combine all images (medium with junk):\n",
    "par_all_image_paths = par_medium_image_paths + par_junk_image_paths\n",
    "par_all_classes = par_medium_classes + par_junk_classes\n",
    "\n",
    "# make full dataset and loader:\n",
    "par_all_dataset = Dataset(par_all_image_paths, par_all_classes, data_transforms, True)\n",
    "par_all_loader = DataLoader(par_all_dataset , batch_size=32, shuffle=True)\n",
    "\n",
    "print(\"Train Images: {} | Query Images: {}\".format(len(par_all_image_paths), len(par_query_image_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## data computation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPPnjjR-A9uI"
   },
   "outputs": [],
   "source": [
    "def train_data(model, train_dset, print_opt=True):\n",
    "    train_features = []\n",
    "    train_images = []\n",
    "    \n",
    "    for idx, (img, name) in enumerate(train_dset):\n",
    "        if print_opt:\n",
    "            print(\"Image {} / {}\".format(idx+1, len(train_dset)), end=\"\\r\")\n",
    "        \n",
    "        # unnormalize image and save        \n",
    "        save_img = img/2 + 0.5\n",
    "        save_img = np.transpose(save_img.numpy(), (1, 2, 0))\n",
    "        save_img = cv2.normalize(save_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "        save_img = save_img.astype(np.uint8)\n",
    "        train_images.append(save_img)\n",
    "        \n",
    "        # compute feature for img\n",
    "        img = img.unsqueeze(0)\n",
    "        feature = model(img.to(\"cuda\"))\n",
    "        train_features.append(Tensor.cpu(feature).detach().numpy())\n",
    "        \n",
    "    # converting to numpy arrays\n",
    "    trn_features = np.array(train_features).reshape((len(train_features),train_features[0].shape[1]))\n",
    "    trn_images = np.array(train_images)\n",
    "\n",
    "    # displaying shapes\n",
    "    if print_opt:\n",
    "        print(\"Features shape: {} | Images shape: {}\".format(trn_features.shape, trn_images.shape), end=\"\\r\")\n",
    "    return trn_features, trn_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErYA4mxjEUSh"
   },
   "outputs": [],
   "source": [
    "def valid_data(model, valid_dset, print_opt=True):\n",
    "    valid_features = []\n",
    "    valid_images = []\n",
    "\n",
    "    for idx, (img, name) in enumerate(valid_dset):\n",
    "        if print_opt:\n",
    "            print(\"Image {} / {}\".format(idx+1, len(valid_dset)), end=\"\\r\")\n",
    "        \n",
    "        # unnormalize image and save        \n",
    "        save_img = img/2 + 0.5\n",
    "        save_img = np.transpose(save_img.numpy(), (1, 2, 0))\n",
    "        save_img = cv2.normalize(save_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "        save_img = save_img.astype(np.uint8)\n",
    "        valid_images.append(save_img)\n",
    "        \n",
    "        # compute feature for img\n",
    "        img = img.unsqueeze(0)\n",
    "        feature = model(img.to(\"cuda\"))\n",
    "        valid_features.append(Tensor.cpu(feature).detach().numpy())\n",
    "\n",
    "    # converting to numpy arrays\n",
    "    val_features = np.array(valid_features).reshape((len(valid_features),valid_features[0].shape[1]))\n",
    "    val_images = np.array(valid_images)\n",
    "\n",
    "    # displaying shapes\n",
    "    if print_opt:\n",
    "        print(\"Features shape: {} | Images shape: {}\".format(val_features.shape, val_images.shape), end=\"\\r\")\n",
    "    return val_features, val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(trn_features, val_features, dim=128, print_opt=True):\n",
    "    # PCA Dimension reduction\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca.fit(trn_features)\n",
    "\n",
    "    # Dimension reduction\n",
    "    trn_features = pca.transform(trn_features)\n",
    "    val_features = pca.transform(val_features)\n",
    "\n",
    "    if print_opt:\n",
    "        print(\"Train Features shape: {} | Valid Features shape: {}\".format(trn_features.shape, val_features.shape))\n",
    "    \n",
    "    return trn_features, val_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Diffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offline_result(i):\n",
    "    ids = trunc_ids[i]\n",
    "    trunc_lap = lap_alpha[ids][:, ids]\n",
    "    scores, _ = linalg.cg(trunc_lap, trunc_init, tol=1e-6, maxiter=20)\n",
    "    return scores\n",
    "\n",
    "class Diffusion(object):\n",
    "    \"\"\"Diffusion class\n",
    "    \"\"\"\n",
    "    def __init__(self, features, cache_dir):\n",
    "        self.features = features\n",
    "        self.N = len(self.features)\n",
    "        self.cache_dir = cache_dir\n",
    "        # use ANN for large datasets\n",
    "        self.use_ann = self.N >= 100000\n",
    "        if self.use_ann:\n",
    "            self.ann = ANN(self.features, method='cosine')\n",
    "        self.knn = KNN(self.features, method='cosine')\n",
    "\n",
    "    def get_offline_results(self, n_trunc, kd=50):\n",
    "        \"\"\"Get offline diffusion results for each gallery feature\n",
    "        \"\"\"\n",
    "        global trunc_ids, trunc_init, lap_alpha\n",
    "        if self.use_ann:\n",
    "            _, trunc_ids = self.ann.search(self.features, n_trunc)\n",
    "            sims, ids = self.knn.search(self.features, kd)\n",
    "            lap_alpha = self.get_laplacian(sims, ids)\n",
    "        else:\n",
    "            sims, ids = self.knn.search(self.features, n_trunc)\n",
    "            trunc_ids = ids\n",
    "            lap_alpha = self.get_laplacian(sims[:, :kd], ids[:, :kd])\n",
    "        trunc_init = np.zeros(n_trunc)\n",
    "        trunc_init[0] = 1\n",
    "\n",
    "        results = Parallel(n_jobs=-1, prefer='threads')(delayed(get_offline_result)(i)\n",
    "                                      for i in range(self.N))\n",
    "        all_scores = np.concatenate(results)\n",
    "\n",
    "        rows = np.repeat(np.arange(self.N), n_trunc)\n",
    "        offline = sparse.csr_matrix((all_scores, (rows, trunc_ids.reshape(-1))),\n",
    "                                    shape=(self.N, self.N),\n",
    "                                    dtype=np.float32)\n",
    "        return offline\n",
    "\n",
    "    def get_laplacian(self, sims, ids, alpha=0.99):\n",
    "        \"\"\"Get Laplacian_alpha matrix\n",
    "        \"\"\"\n",
    "        affinity = self.get_affinity(sims, ids)\n",
    "        num = affinity.shape[0]\n",
    "        degrees = affinity @ np.ones(num) + 1e-12\n",
    "        # mat: degree matrix ^ (-1/2)\n",
    "        mat = sparse.dia_matrix(\n",
    "            (degrees ** (-0.5), [0]), shape=(num, num), dtype=np.float32)\n",
    "        stochastic = mat @ affinity @ mat\n",
    "        sparse_eye = sparse.dia_matrix(\n",
    "            (np.ones(num), [0]), shape=(num, num), dtype=np.float32)\n",
    "        lap_alpha = sparse_eye - alpha * stochastic\n",
    "        return lap_alpha\n",
    "\n",
    "    def get_affinity(self, sims, ids, gamma=3):\n",
    "        \"\"\"Create affinity matrix for the mutual kNN graph of the whole dataset\n",
    "        Args:\n",
    "            sims: similarities of kNN\n",
    "            ids: indexes of kNN\n",
    "        Returns:\n",
    "            affinity: affinity matrix\n",
    "        \"\"\"\n",
    "        num = sims.shape[0]\n",
    "        sims[sims < 0] = 0  # similarity should be non-negative\n",
    "        sims = sims ** gamma\n",
    "        # vec_ids: feature vectors' ids\n",
    "        # mut_ids: mutual (reciprocal) nearest neighbors' ids\n",
    "        # mut_sims: similarites between feature vectors and their mutual nearest neighbors\n",
    "        vec_ids, mut_ids, mut_sims = [], [], []\n",
    "        for i in range(num):\n",
    "            # check reciprocity: i is in j's kNN and j is in i's kNN when i != j\n",
    "            ismutual = np.isin(ids[ids[i]], i).any(axis=1)\n",
    "            ismutual[0] = False\n",
    "            if ismutual.any():\n",
    "                vec_ids.append(i * np.ones(ismutual.sum(), dtype=int))\n",
    "                mut_ids.append(ids[i, ismutual])\n",
    "                mut_sims.append(sims[i, ismutual])\n",
    "        vec_ids, mut_ids, mut_sims = map(np.concatenate, [vec_ids, mut_ids, mut_sims])\n",
    "        affinity = sparse.csc_matrix((mut_sims, (vec_ids, mut_ids)),\n",
    "                                     shape=(num, num), dtype=np.float32)\n",
    "        return affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKNN(object):\n",
    "    \"\"\"KNN base class\"\"\"\n",
    "    def __init__(self, database, method):\n",
    "        if database.dtype != np.float32:\n",
    "            database = database.astype(np.float32)\n",
    "        self.N = len(database)\n",
    "        self.D = database[0].shape[-1]\n",
    "        self.database = database if database.flags['C_CONTIGUOUS'] \\\n",
    "                               else np.ascontiguousarray(database)\n",
    "\n",
    "    def add(self, batch_size=10000):\n",
    "        \"\"\"Add data into index\"\"\"\n",
    "        if self.N <= batch_size:\n",
    "            self.index.add(self.database)\n",
    "        else:\n",
    "            [self.index.add(self.database[i:i+batch_size])\n",
    "                    for i in tqdm(range(0, len(self.database), batch_size),\n",
    "                                  desc='[index] add')]\n",
    "\n",
    "    def search(self, queries, k):\n",
    "        \"\"\"Search\n",
    "        Args:\n",
    "            queries: query vectors\n",
    "            k: get top-k results\n",
    "        Returns:\n",
    "            sims: similarities of k-NN\n",
    "            ids: indexes of k-NN\n",
    "        \"\"\"\n",
    "        if not queries.flags['C_CONTIGUOUS']:\n",
    "            queries = np.ascontiguousarray(queries)\n",
    "        if queries.dtype != np.float32:\n",
    "            queries = queries.astype(np.float32)\n",
    "        sims, ids = self.index.search(queries, k)\n",
    "        return sims, ids\n",
    "\n",
    "\n",
    "class KNN(BaseKNN):\n",
    "    \"\"\"KNN class\n",
    "    Args:\n",
    "        database: feature vectors in database\n",
    "        method: distance metric\n",
    "    \"\"\"\n",
    "    def __init__(self, database, method):\n",
    "        super().__init__(database, method)\n",
    "        self.index = {'cosine': faiss.IndexFlatIP,\n",
    "                      'euclidean': faiss.IndexFlatL2}[method](self.D)\n",
    "        if os.environ.get('CUDA_VISIBLE_DEVICES'):\n",
    "            self.index = faiss.index_cpu_to_all_gpus(self.index)\n",
    "        self.add()\n",
    "\n",
    "\n",
    "class ANN(BaseKNN):\n",
    "    \"\"\"Approximate nearest neighbor search class\n",
    "    Args:\n",
    "        database: feature vectors in database\n",
    "        method: distance metric\n",
    "    \"\"\"\n",
    "    def __init__(self, database, method, M=128, nbits=8, nlist=316, nprobe=64):\n",
    "        super().__init__(database, method)\n",
    "        self.quantizer = {'cosine': faiss.IndexFlatIP,\n",
    "                          'euclidean': faiss.IndexFlatL2}[method](self.D)\n",
    "        self.index = faiss.IndexIVFPQ(self.quantizer, self.D, nlist, M, nbits)\n",
    "        samples = database[np.random.permutation(np.arange(self.N))[:self.N // 5]]\n",
    "        print(\"[ANN] train\")\n",
    "        self.index.train(samples)\n",
    "        self.add()\n",
    "        self.index.nprobe = nprobe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "pKX66jYNISuW"
   },
   "source": [
    "## Image retrieval functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(train_data, queries):\n",
    "    D = cosine_similarity(queries, train_data)\n",
    "    indexes = np.argsort(1-D)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion(train_data, queries):\n",
    "    cache_dir = \"cache\"\n",
    "    kd = 50\n",
    "    truncation_size = 586\n",
    "    \n",
    "    n_queries = len(queries)\n",
    "    diffusion = Diffusion(np.vstack([queries, train_data]), cache_dir)\n",
    "    \n",
    "    offline = diffusion.get_offline_results(truncation_size, kd)\n",
    "    \n",
    "    features = preprocessing.normalize(offline, norm=\"l2\", axis=1)\n",
    "    \n",
    "    scores = features[:n_queries] @ features[n_queries:].T\n",
    "    \n",
    "    ranks = np.argsort(-scores.toarray())\n",
    "    \n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70a7ZiLUELks"
   },
   "outputs": [],
   "source": [
    "def image_retrieval_k(train_data, test_data, train_names, test_names, train_images, test_images, k=10, view_option=0, border_size=3, print_opt=True, diff=False):\n",
    "    avg_precisions = []\n",
    "    precisionsatk = []\n",
    "    count = 0\n",
    "    \n",
    "    # Finding similarity order:\n",
    "    if diff:\n",
    "        indexes = diffusion(train_data, test_data)\n",
    "    else:\n",
    "        indexes = cosine_sim(train_data, test_data)\n",
    "        \n",
    "    for idx, index in enumerate(indexes):\n",
    "        all_precisions = []\n",
    "        precisions = []\n",
    "        \n",
    "        # Finding the index of the last correct image in the sorted index to iter to\n",
    "        last_correct_image_idx = 0\n",
    "        for i in range(len(index)):\n",
    "            if train_names[index[i]] == test_names[idx]:\n",
    "                last_correct_image_idx = i\n",
    "        \n",
    "        # make sure we iter to k (for precision@k) if all correct images are found before k\n",
    "        if k > last_correct_image_idx:\n",
    "            last_correct_image_idx = k+1\n",
    "        \n",
    "        # Itering through all images untill we get to k or last correct image to compute AP\n",
    "        for kk in range(1, last_correct_image_idx+2):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            \n",
    "            # Finding the correct amount of images in the training set\n",
    "            correct_count = 0\n",
    "            for ind in index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    correct_count += 1\n",
    "            sized_index = index[:kk]\n",
    "            \n",
    "            # Find TP FP FN\n",
    "            for ind in sized_index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            FN = correct_count - TP\n",
    "            \n",
    "            # If the last k image is a correct image we add precision to the list\n",
    "            if train_names[sized_index[-1]] == test_names[idx]:\n",
    "                precisions.append(TP/(TP+FP))\n",
    "\n",
    "            # Adding all precisions and recalls to a seperate list\n",
    "            all_precisions.append(TP/(TP+FP))\n",
    "        \n",
    "        # Solving AP and precision@k\n",
    "        avg_precisions.append(np.average(precisions))\n",
    "        precisionsatk.append(all_precisions[k-1])\n",
    "        \n",
    "        # display retrieval:\n",
    "        if view_option == 0:\n",
    "            count += 1\n",
    "            if print_opt:\n",
    "                print(\"Percentage Complete: {}%\".format(round((count/len(test_data))*100),2), end=\"\\r\")\n",
    "        elif view_option == 1:\n",
    "            display_retrieval(test_data, test_images, idx, train_images, index, test_names, train_names, sized_index, avg_precisions[-1], precisionsatk[-1], border_size, k)\n",
    "            \n",
    "    return avg_precisions, precisionsatk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def display_retrieval(test_data, test_images, idx, train_images, index, test_names, train_names, sized_index, avg_precisions, precisionsatk, border_size, k):\n",
    "    top_k_images = [test_images[idx]]\n",
    "    for i in range(0,k):\n",
    "        top_k_images.append(train_images[index[i]])\n",
    "\n",
    "    fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "    for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "        if i == 0:\n",
    "            query_name = test_names[idx]\n",
    "            title = \"Query: {}\".format(query_name)\n",
    "        else:\n",
    "            title = train_names[sized_index[i-1]]\n",
    "            if train_names[sized_index[i-1]] == query_name:\n",
    "                color = (0, 255, 0)\n",
    "                image = border(image, color, border_size)\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "                image = border(image, color, border_size)\n",
    "        # display all set options\n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(\"Label: {}\".format(test_names[idx]))\n",
    "    print(\"Average Precision for query {}: \".format(idx), avg_precisions)\n",
    "    print(\"Precision@k for query {}: \".format(idx), precisionsatk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KU98mwvtM7XF"
   },
   "outputs": [],
   "source": [
    "def border(img, color, border_size):\n",
    "    # get dimensions\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # make a base slightly bigger than image\n",
    "    base_size= h+(border_size*2), w+(border_size*2), 3\n",
    "    base = np.zeros(base_size, dtype=np.uint8)\n",
    "\n",
    "    # make a boundary of chosen color\n",
    "    cv2.rectangle(base, (0,0), (w+20,h+20), color, 30)\n",
    "\n",
    "    # put original image into base\n",
    "    base[border_size:h+border_size, border_size:w+border_size] = img\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map(model, dataset, difficulty, pca_opt=64, view=0, print_opt=True, diff=False):\n",
    "    run = True\n",
    "    # finding correct imports\n",
    "    if dataset == 'oxford':\n",
    "        names = ox_names\n",
    "        query_dataset = ox_query_dataset\n",
    "        query_classes = ox_query_classes\n",
    "        if difficulty == 'easy':\n",
    "            train_dataset = ox_easy_dataset\n",
    "            train_classes = ox_easy_classes\n",
    "        elif difficulty == 'medium':\n",
    "            train_dataset = ox_medium_dataset\n",
    "            train_classes = ox_medium_classes\n",
    "        elif difficulty == 'hard':\n",
    "            train_dataset = ox_hard_dataset\n",
    "            train_classes = ox_hard_classes\n",
    "        else:\n",
    "            print(\"Unkown mode: Try 'easy', 'medium', or 'hard'\")\n",
    "            run = False\n",
    "    elif dataset == 'paris':\n",
    "        names = par_names\n",
    "        query_dataset = par_query_dataset\n",
    "        query_classes = par_query_classes\n",
    "        if difficulty == 'easy':\n",
    "            train_dataset = par_easy_dataset\n",
    "            train_classes = par_easy_classes\n",
    "        elif difficulty == 'medium':\n",
    "            train_dataset = par_medium_dataset\n",
    "            train_classes = par_medium_classes\n",
    "        elif difficulty == 'hard':\n",
    "            train_dataset = par_hard_dataset\n",
    "            train_classes = par_hard_classes\n",
    "        else:\n",
    "            print(\"Unkown mode: Try 'easy', 'medium', or 'hard'\") \n",
    "            run = False\n",
    "    else:\n",
    "        print(\"Unknown dataset: Try 'oxford' or 'paris'\")\n",
    "        run = False\n",
    "    \n",
    "    if run:\n",
    "        # loading in training data\n",
    "        if print_opt:\n",
    "            print(\"Loading Training features...\")\n",
    "        trn_features, trn_images = train_data(model, train_dataset, print_opt)\n",
    "\n",
    "        # loading in validation data\n",
    "        if print_opt:\n",
    "            print(\"\\n\\nLoading Query features...\")\n",
    "        val_features, val_images = valid_data(model, query_dataset, print_opt)\n",
    "\n",
    "        # computing names\n",
    "        trn_names = np.array([names[idx] for idx in train_classes])\n",
    "        val_names = np.array([names[idx] for idx in query_classes])\n",
    "\n",
    "        # normalization\n",
    "        n_queries = len(val_features)\n",
    "        features = np.vstack([val_features, trn_features])\n",
    "        features = preprocessing.normalize(features, norm=\"l2\", axis=0)\n",
    "        val_features = features[:n_queries]\n",
    "        trn_features = features[n_queries:]\n",
    "\n",
    "        # compute PCA for dimension reduction\n",
    "        if pca_opt != 0:\n",
    "            if print_opt:\n",
    "                print(\"\\n\\nComputing PCA dimension reduction...\")\n",
    "            trn_pca, val_pca = pca(trn_features, val_features, pca_opt, print_opt)\n",
    "        else:\n",
    "            print(\"\")\n",
    "            trn_pca, val_pca = trn_features, val_features\n",
    "\n",
    "        # compute mAP (can display retrieval)\n",
    "        if print_opt:\n",
    "            print(\"\\nComputing mAP...\")\n",
    "        AP, precisionsatk = image_retrieval_k(trn_pca, val_pca, trn_names, val_names, trn_images, val_images, 10, view, 15, print_opt, diff)\n",
    "        mAP = np.mean(AP)\n",
    "        if print_opt:\n",
    "            print(\"\\n\\nmAP = {}\".format(mAP))\n",
    "        \n",
    "        return trn_features, trn_names, val_features, val_names, AP, precisionsatk, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pixel(names, query_dataset, query_classes, train_dataset, train_classes):\n",
    "    trn_names = np.array([names[idx] for idx in train_classes])\n",
    "    val_names = np.array([names[idx] for idx in query_classes])\n",
    "\n",
    "    val_images = []\n",
    "    for i in query_dataset:\n",
    "        img = i[0]\n",
    "        save_img = img/2 + 0.5\n",
    "        save_img = np.transpose(save_img.numpy(), (1, 2, 0))\n",
    "        save_img = cv2.normalize(save_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "        save_img = save_img.astype(np.uint8)\n",
    "        val_images.append(save_img)\n",
    "    val_images = np.array(val_images)\n",
    "\n",
    "    trn_images = []\n",
    "    for i in train_dataset:\n",
    "        img = i[0]\n",
    "        save_img = img/2 + 0.5\n",
    "        save_img = np.transpose(save_img.numpy(), (1, 2, 0))\n",
    "        save_img = cv2.normalize(save_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "        save_img = save_img.astype(np.uint8)\n",
    "        trn_images.append(save_img)\n",
    "    trn_images = np.array(trn_images)\n",
    "    \n",
    "    val_pixels = []\n",
    "    for i in val_images:\n",
    "        img = cv2.cvtColor(i, cv2.COLOR_RGB2GRAY)\n",
    "        pix = img.reshape((50176))\n",
    "        val_pixels.append(pix)\n",
    "\n",
    "    trn_pixels = []\n",
    "    for i in trn_images:\n",
    "        img = cv2.cvtColor(i, cv2.COLOR_RGB2GRAY)\n",
    "        pix = img.reshape((50176))\n",
    "        trn_pixels.append(pix) \n",
    "\n",
    "    val_pixels = np.array(val_pixels)\n",
    "    trn_pixels = np.array(trn_pixels)\n",
    "\n",
    "    return trn_pixels, val_pixels, trn_names, val_names, trn_images, val_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Finding Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(m, dataloader):\n",
    "    criterion = losses.CircleLoss(m=0.4, gamma=80)\n",
    "    optimizer = optim.AdamW(m.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "    lr_finder = LRFinder(m, optimizer, criterion, device=\"cuda\")\n",
    "    lr_finder.range_test(dataloader, end_lr=10, num_iter=100)\n",
    "    lr_finder.plot()\n",
    "    lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "U-G6o71aIUuD"
   },
   "source": [
    "## Visualization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLXY1fRvqn0H"
   },
   "outputs": [],
   "source": [
    "# visualization for a given query image:\n",
    "def visualize_query(dataset, difficulty, query, query_name, train_data, train_names, k):\n",
    "    # Finding the euclidean distance from the query image and sorting them into index\n",
    "    query = query.reshape((1, -1))\n",
    "    D = euclidean_distances(train_data, query).squeeze()\n",
    "    index = np.argsort(D)\n",
    "\n",
    "    # grab only the k closest points\n",
    "    data = []\n",
    "    name = []\n",
    "    for idx in index[:k]:\n",
    "        data.append(train_data[idx])\n",
    "        name.append(train_names[idx])\n",
    "  \n",
    "    joined_data = np.concatenate((query, np.array(data)))\n",
    "    # create tsne\n",
    "    tsne = TSNE(random_state=42)\n",
    "    joined_tsne = tsne.fit_transform(joined_data)\n",
    "\n",
    "    X_tsne = joined_tsne[1:]\n",
    "    query_tsne = joined_tsne[:1]\n",
    "\n",
    "    #sorting based on class label:\n",
    "    sort_idx = np.argsort(name)\n",
    "    sorted_names = []\n",
    "    sorted_tSNE = []\n",
    "    for i in sort_idx:\n",
    "        sorted_names.append(name[i])\n",
    "        sorted_tSNE.append(X_tsne[i])\n",
    "    sorted_tSNE = np.array(sorted_tSNE)\n",
    "    \n",
    "    # convert names to integers for graphing function:\n",
    "    names = []\n",
    "    y = []\n",
    "    counter = []\n",
    "    count = -1\n",
    "    start = 0\n",
    "    for i in sorted_names:\n",
    "        if i not in names:\n",
    "            counter.append(start)\n",
    "            start = 0\n",
    "            names.append(i)\n",
    "            count += 1\n",
    "        start += 1\n",
    "        y.append(count)\n",
    "    counter.append(start)\n",
    "\n",
    "    # setting colours:\n",
    "    colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\", \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\", \"blue\"]\n",
    "    if len(names) > len(colors)+1:\n",
    "        # setting colours:\n",
    "        colors = []\n",
    "        for i in range(len(y)+1):\n",
    "            r = random.random()\n",
    "            b = random.random()\n",
    "            g = random.random()\n",
    "            colors.append((r, g, b))\n",
    "\n",
    "\n",
    "  # Plot output:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if X_tsne[:, 0].min() < 0:\n",
    "        x = 1.5\n",
    "    else:\n",
    "        x=-1.5\n",
    "    if X_tsne[:, 1].min() < 0:\n",
    "        xx = 1.5\n",
    "    else:\n",
    "        xx = -1.5\n",
    "    plt.xlim(sorted_tSNE[:, 0].min()*x, sorted_tSNE[:, 0].max()*1.5)\n",
    "    plt.ylim(sorted_tSNE[:, 1].min()*xx, sorted_tSNE[:, 1].max()*1.5)\n",
    "\n",
    "    for i in range(len(X_tsne)):\n",
    "        plt.text(sorted_tSNE[i, 0], sorted_tSNE[i, 1], str(y[i]), color = colors[y[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.text(query_tsne[0, 0], query_tsne[0, 1], \".\", color=(1,0,0), fontdict={'weight': 'bold', 'size': 40})\n",
    "    plt.title(\"t-SNE for {}-{} for k = {}\".format(dataset, difficulty, k))\n",
    "    plt.ylabel(\"t-SNE feature 0\")\n",
    "    plt.xlabel(\"t-SNE feature 1\")\n",
    "    plt.show()\n",
    "\n",
    "    # print information relating to plot:\n",
    "    print(\"Query Image: {} | Red Square\\n\".format(query_name))\n",
    "\n",
    "    print(f'{\"NAME\":<20s} {\"NUMBER\":<10s} {\"COUNT\":<5s}')\n",
    "    for idx, name, count in zip(range(len(names)), names, counter[1:]):\n",
    "        print(f'{name:<20s} {str(idx):<10s} {str(count):<5s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class(dataset, difficulty, class_name, filenames, features, model_name, save_folder=None):    \n",
    "    # create tsne\n",
    "    tsne = TSNE(random_state=42)\n",
    "    X_tsne = tsne.fit_transform(features)\n",
    "    \n",
    "    if class_name[0] == \"all\":\n",
    "        class_tSNE = X_tsne\n",
    "        class_names = filenames\n",
    "    else:\n",
    "        # select only class related features\n",
    "        class_tSNE = []\n",
    "        class_names = []\n",
    "        for t, name in zip(X_tsne, filenames):\n",
    "            if name in class_name:\n",
    "                class_tSNE.append(t)\n",
    "                class_names.append(name)\n",
    "        class_tSNE = np.array(class_tSNE)\n",
    "    \n",
    "    #sorting based on class label:\n",
    "    sort_idx = np.argsort(class_names)\n",
    "    sorted_names = []\n",
    "    sorted_tSNE = []\n",
    "    for i in sort_idx:\n",
    "        sorted_names.append(class_names[i])\n",
    "        sorted_tSNE.append(class_tSNE[i])\n",
    "    sorted_tSNE = np.array(sorted_tSNE)\n",
    "        \n",
    "    # convert names to integers for graphing function:\n",
    "    names = []\n",
    "    y = []\n",
    "    counter = []\n",
    "    count = -1\n",
    "    start = 0\n",
    "    for i in sorted_names:\n",
    "        if i not in names:\n",
    "            counter.append(start)\n",
    "            start = 0\n",
    "            names.append(i)\n",
    "            count += 1\n",
    "        start += 1\n",
    "        y.append(count)\n",
    "    counter.append(start)\n",
    "\n",
    "    # setting colours:\n",
    "    colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\", \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\", \"blue\"]\n",
    "    if len(names) > len(colors)+1:\n",
    "        # setting colours:\n",
    "        colors = []\n",
    "        for i in range(len(y)+1):\n",
    "            r = random.random()\n",
    "            b = random.random()\n",
    "            g = random.random()\n",
    "            colors.append((r, g, b))\n",
    "\n",
    "\n",
    "  # Plot output:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if X_tsne[:, 0].min() < 0:\n",
    "        x = 1.5\n",
    "    else:\n",
    "        x=-1.5\n",
    "    if X_tsne[:, 1].min() < 0:\n",
    "        xx = 1.5\n",
    "    else:\n",
    "        xx = -1.5\n",
    "    plt.xlim(sorted_tSNE[:, 0].min()*x, sorted_tSNE[:, 0].max()*1.5)\n",
    "    plt.ylim(sorted_tSNE[:, 1].min()*xx, sorted_tSNE[:, 1].max()*1.5)\n",
    "\n",
    "    for i in range(len(class_tSNE)):\n",
    "        plt.text(sorted_tSNE[i, 0], sorted_tSNE[i, 1], str(y[i]), color = colors[y[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.title(\"t-SNE w. {} for {}-{}\".format(model_name, dataset, difficulty))\n",
    "\n",
    "    plt.ylabel(\"t-SNE feature 0\")\n",
    "    plt.xlabel(\"t-SNE feature 1\")\n",
    "        \n",
    "    if save_folder != None:\n",
    "        # save figure to set folder\n",
    "        plt.savefig(save_folder)\n",
    "    else:\n",
    "        plt.show()\n",
    "        # print information relating to plot:\n",
    "        print(f'{\"NAME\":<20s} {\"NUMBER\":<10s} {\"COUNT\":<5s}')\n",
    "        for idx, name, count in zip(range(len(names)), names, counter[1:]):\n",
    "            print(f'{name:<20s} {str(idx):<10s} {str(count):<5s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "a6WpYfksM_ZB"
   },
   "source": [
    "## Retreival:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a model\n",
    "m = load_model('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pre fine tuned models\n",
    "m = load_ft(m, 'resnet', 'oxford')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "find_lr(m, ox_all_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune model\n",
    "iteration_loss, epoch_loss, maps = fine_tune(ox_all_loader, m, epochs=50, lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and map over epoch/iteration when finetuning\n",
    "plot_loss(iteration_loss, epoch_loss, maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute map for specific dataset\n",
    "model = m.eval()\n",
    "dataset = 'oxford'\n",
    "difficulty = 'easy'\n",
    "view = 0\n",
    "pca_opt = 0\n",
    "print_opt = True\n",
    "diff = True\n",
    "\n",
    "trn_features, trn_names, val_features, val_names, AP, precisionsatk, mAP = compute_map(model, dataset, difficulty, pca_opt, view, print_opt, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pixel:\n",
    "names = ox_names\n",
    "query_dataset = ox_query_dataset\n",
    "query_classes = ox_query_classes\n",
    "train_dataset = ox_easy_dataset\n",
    "train_classes = ox_easy_classes\n",
    "view = 1\n",
    "\n",
    "trn_pixels, val_pixels, trn_names, val_names, trn_images, val_images = compute_pixel(names, query_dataset, query_classes, train_dataset, train_classes)\n",
    "\n",
    "AP, precisionsatk = image_retrieval_k(trn_pixels, val_pixels, trn_names, val_names, trn_images, val_images, 10, view, 15, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "lhx_7wOiKHGT"
   },
   "source": [
    "## Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize query -> hard queries = 8, 43, 50\n",
    "# displays query image, its average precision (AP) and where it fits with all the training points (red square is query image)\n",
    "# choose query idx\n",
    "idx = 0\n",
    "\n",
    "# display query + AP\n",
    "plt.imshow(val_images[idx])\n",
    "plt.title(\"Query Image | {} | AP={}\".format(val_names[idx], np.round(AP[idx], 4)))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# visualize query w.r.t training data\n",
    "visualize_query(dataset, difficulty, val_features[idx], val_names[idx], trn_features, trn_names, k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize all data: [\"all\"], else [\"name1\", \"name2\", etc]\n",
    "visualize_class(dataset, difficulty, [\"all\"], trn_names, trn_features, \"ResNet-ft\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pKX66jYNISuW",
    "P48WGodeKn4Z"
   ],
   "name": "VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
